const fs = require('fs');
const path = require('path');
const StateManager = require('./state-manager');
const ImageGenerator = require('../image/image-generator');
const VideoCoordinator = require('../video/video-coordinator');
const { getMoengageEmailPublisher } = require('../integrations/moengage-email-publisher');
const { getMoengageClient } = require('../integrations/moengage-client');

class SocialMediaOrchestrator {
  constructor(options = {}) {
    this.projectRoot = options.projectRoot || process.cwd();
    this.simulate = options.simulate || false;
    this.limit = options.limit || null;

    this.stateManager = new StateManager(path.join(this.projectRoot, 'data'));
  }

  _getLatestCampaignPlanningEntry(topic) {
    const campaigns = this.stateManager?.state?.campaigns || {};
    const entries = Object.values(campaigns).filter(Boolean);

    const planningEntries = entries.filter((entry) => {
      const stageId = entry?.stageId;
      const type = typeof entry?.type === 'string' ? entry.type : '';
      return stageId === 1 || type.includes('campaign-planning');
    });

    if (planningEntries.length === 0) return null;

    const byCompletedAtDesc = (a, b) => {
      const aTs = new Date(a?.completedAt || a?.updatedAt || a?.createdAt || 0).getTime();
      const bTs = new Date(b?.completedAt || b?.updatedAt || b?.createdAt || 0).getTime();
      return bTs - aTs;
    };

    const normalizedTopic = (topic || '').trim().replace(/\s+/g, ' ');
    if (normalizedTopic) {
      const match = planningEntries
        .filter((e) => (e?.topic || '').trim().replace(/\s+/g, ' ') === normalizedTopic)
        .sort(byCompletedAtDesc)[0];
      if (match) return match;
    }

    return planningEntries.sort(byCompletedAtDesc)[0];
  }

  /**
   * Extract the "Direct image prompt" paragraph from Stage 1 creative prompt text.
   * Used so WhatsApp creative image generation adheres to the detailed prompt from planning.
   * @param {string} creativePromptText - Full Stage 1 creative prompt (may include markdown)
   * @returns {string|null} The direct image prompt paragraph, or null if not found
   */
  _extractDirectImagePrompt(creativePromptText) {
    if (!creativePromptText || typeof creativePromptText !== 'string') return null;
    const text = creativePromptText.trim();
    if (!text) return null;

    const marker = /Direct image prompt\s*(?:\([^)]*\))?\s*:?\s*/i;
    const match = text.match(marker);
    if (!match) return null;

    const startIdx = text.indexOf(match[0]) + match[0].length;
    let afterMarker = text.slice(startIdx).trim();
    afterMarker = afterMarker.replace(/^\s*\*+\s*/, '');
    const endOfParagraph = afterMarker.search(/\n\s*\n/);
    const paragraph = (endOfParagraph === -1 ? afterMarker : afterMarker.slice(0, endOfParagraph)).trim();
    return paragraph.length > 30 ? paragraph : null;
  }

  async _generateHeyGenScript(options) {
    const topic = options.topic || 'PL Capital investing insights';
    const platform = options.platform || 'instagram';
    const format = options.format || 'reel';
    const duration = Number(options.duration || 8);
    const language = options.language || 'english';

    const wordsTarget = Math.max(12, Math.round(duration * 2.2)); // ~2.2 wps for clear speech
    const groqKey = process.env.GROQ_API_KEY;

    const planning = this._getLatestCampaignPlanningEntry(topic);
    const planningText = (planning?.creativePrompt || planning?.output || '').trim();

    if (!groqKey) {
      const needsDisclaimer = /(english|hinglish)/i.test(language);
      const disclaimer = needsDisclaimer ? 'Market risks apply.' : '';
      const hook = platform === 'instagram' ? 'Stop scrollingâ€”quick money tip.' : 'Quick update.';
      return `${hook} ${topic}. Want a simple plan? Talk to PL Capital today. ${disclaimer}`.trim();
    }

    const systemPrompt = `You write short, natural spoken scripts for a financial services video avatar.
Return ONLY the spoken script as plain text. No bullet points. No headings. No stage directions. No meta-instructions.`;

    const languageName = this._getLanguageName(language);
    const isInstagramReel = platform === 'instagram' || /reel/i.test(format || '');
    const isYouTubeShort = platform === 'youtube' || /short/i.test(format || '') || /youtube-short/i.test(options.type || '');
    const needsDisclaimer = /(english|hinglish)/i.test(language);
    const viralReelStyle = `Style (viral reel/short, Indian audience):
- Hook in the first sentence (pattern interrupt â€” stop the scroll).
- Short punchy sentences, spoken like a credible Indian finfluencer (not cheesy).
- Use everyday India cues where relevant (â‚¹, SIP, tax, salary day) without giving personalized advice.
- Close with a strong CTA: "Save this", "Share", "Follow", or "Comment 'PLAN'".`;
    const styleGuidance = (isInstagramReel || isYouTubeShort) ? viralReelStyle : '';
    const userPrompt = `Write a single spoken script for an AI avatar video.

Constraints:
- Platform: ${platform}
- Format: ${format}
- Topic: ${topic}
- Duration: ${duration} seconds
- Language: ${languageName}
- Tone: confident, warm, professional, Indian business style.
- Length: about ${wordsTarget} words (max ${wordsTarget + 6}).
- Compliance: no guaranteed returns, no exaggerated claims, no personalized investment advice.
- If language is English or Hinglish, end with the exact disclaimer: "Market risks apply." (exactly once).

${styleGuidance ? styleGuidance : ''}

Optional context from Stage 1 planning (may include purpose/audience/tone):
${planningText ? planningText.slice(0, 2000) : '(none)'}

Output rules:
- Output ONLY the script text the avatar should speak.
- Do NOT include quotation marks or labels like "Script:".`;

    const model = process.env.GROQ_HEYGEN_SCRIPT_MODEL || 'llama-3.3-70b-versatile';

    const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
      method: 'POST',
      headers: {
        Authorization: `Bearer ${groqKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        model,
        messages: [
          { role: 'system', content: systemPrompt },
          { role: 'user', content: userPrompt }
        ],
        temperature: 0.6,
        max_tokens: 400
      })
    });

    if (!response.ok) {
      const text = await response.text().catch(() => '');
      throw new Error(text || `Groq API error: ${response.status}`);
    }

    const data = await response.json();
    let script = (data.choices?.[0]?.message?.content || '').trim();

    script = script.replace(/^```[\s\S]*?$/gm, '').trim();
    script = script.replace(/^\s*script\s*:\s*/i, '').trim();
    script = script.replace(/^["']|["']$/g, '').trim();

    const words = script.split(/\s+/).filter(Boolean);
    if (words.length > wordsTarget + 12) {
      script = words.slice(0, wordsTarget + 12).join(' ').trim();
    }

    if (needsDisclaimer && !/market risks apply\.?$/i.test(script)) {
      script = `${script.replace(/\.*\s*$/, '')}. Market risks apply.`;
    }

    return script;
  }

  /**
   * Generate Twitter/X thread content (array of tweets, each â‰¤280 chars).
   * Uses Gemini gemini-3-flash-preview when GEMINI_API_KEY is set; otherwise falls back to Groq.
   * @private
   */
  async _generateThreadContent(options) {
    const topic = (options.topic || 'Quick Finance Thread').trim();
    const language = options.language || 'english';
    const planning = this._getLatestCampaignPlanningEntry(topic);
    const planningText = (planning?.creativePrompt || planning?.output || '').trim().slice(0, 2000);

    const defaults = {
      tweets: [
        `ðŸ§µ Thread: ${topic || 'Quick finance insights'}`,
        'Key point 1 â€” clear, punchy. No fluff.',
        'Key point 2 â€” one idea per tweet. Max 280 chars.',
        'Key point 3 â€” actionable or memorable.',
        'Recap + CTA: Save this thread â€¢ Follow for more. Market risks apply.'
      ]
    };

    const systemPrompt = `You are an expert at creating Twitter/X thread content for PL Capital (finance). Your output MUST be valid JSON only, no markdown or explanation.

Output a single JSON object with exactly one key:
- "tweets": array of strings. Each string is ONE tweet (max 280 characters). Typically 5â€“12 tweets for a thread.
  - First tweet: hook (number the thread e.g. "1/7" or "ðŸ§µ", punchy opener).
  - Middle tweets: one clear idea per tweet, educational or insight, compliant (no guaranteed returns).
  - Last tweet: recap or CTA (e.g. "Save this thread â€¢ Follow @PLCapital. Market risks apply.").

Rules: No guaranteed returns, no "sure-shot", no exaggerated claims. Professional, scroll-stopping, thread-native. Language: ${language}.`;

    const userPrompt = `Create a Twitter/X thread for topic: ${topic}
Language: ${language}
${planningText ? `Optional creative direction from planning:\n${planningText}\n` : ''}
Output ONLY the JSON object, no other text.`;

    const parseAndNormalize = (raw) => {
      raw = (raw || '').trim().replace(/^```(?:json)?\s*|\s*```$/g, '').trim();
      const parsed = JSON.parse(raw);
      const tweets = Array.isArray(parsed.tweets) ? parsed.tweets : defaults.tweets;
      return {
        tweets: tweets.slice(0, 15).map((t) => {
          const s = typeof t === 'string' ? t.trim() : String(t).trim();
          return s.length > 280 ? s.slice(0, 277) + '...' : s;
        }).filter(Boolean)
      };
    };

    const geminiKey = process.env.GEMINI_API_KEY;
    if (geminiKey) {
      try {
        const { GoogleGenAI } = await import('@google/genai');
        const ai = new GoogleGenAI({ apiKey: geminiKey });
        const model = 'gemini-3-flash-preview';
        const fullPrompt = `${systemPrompt}\n\n${userPrompt}`;
        const response = await ai.models.generateContent({
          model,
          contents: fullPrompt,
          config: { temperature: 0.6, maxOutputTokens: 2000 }
        });
        let raw = (response?.text ?? '').trim();
        if (!raw && response?.candidates?.[0]?.content?.parts) {
          const textPart = response.candidates[0].content.parts.find((p) => p.text != null);
          raw = (textPart?.text ?? '').trim();
        }
        if (!raw) {
          console.log('   âš ï¸ Gemini thread: empty response');
          return defaults;
        }
        return parseAndNormalize(raw);
      } catch (err) {
        console.log(`   âš ï¸ Gemini thread failed: ${err instanceof Error ? err.message : 'unknown'}`);
      }
    }

    const groqKey = process.env.GROQ_API_KEY;
    if (!groqKey) return defaults;

    try {
      const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${groqKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: process.env.GROQ_THREAD_MODEL || 'llama-3.3-70b-versatile',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
          ],
          temperature: 0.6,
          max_tokens: 2000
        })
      });
      if (!response.ok) {
        const text = await response.text().catch(() => '');
        console.log(`   âš ï¸ Groq thread API error: ${response.status} ${text}`);
        return defaults;
      }
      const data = await response.json();
      const raw = (data.choices?.[0]?.message?.content || '').trim();
      return parseAndNormalize(raw);
    } catch (err) {
      console.log(`   âš ï¸ Thread content generation failed: ${err instanceof Error ? err.message : 'unknown'}`);
      return defaults;
    }
  }

  /**
   * Generate carousel content (slide count, cover, slides) for LinkedIn/Instagram using Groq.
   * Returns { slideCount, coverText, slides: [{ title, body, highlight, visualCue }], finalSlideCta, disclaimerLine }.
   * @private
   */
  async _generateCarouselContent(options) {
    const topic = (options.topic || 'Quick Investing Checklist').trim();
    const platform = options.platform || 'linkedin';
    const language = options.language || 'english';
    const planning = this._getLatestCampaignPlanningEntry(topic);
    const planningText = (planning?.creativePrompt || planning?.output || '').trim().slice(0, 2000);

    const defaults = {
      slideCount: 7,
      coverText: topic || 'Quick Investing Checklist',
      slides: [
        { title: 'Myth 1', body: 'Swipe for the truth.', highlight: 'Busted', visualCue: 'Bold myth vs fact icon' },
        { title: 'Myth 2', body: 'One clear takeaway.', highlight: 'Key idea', visualCue: 'Simple icon + mini chart' },
        { title: 'Myth 3', body: 'One actionable step.', highlight: 'Tip', visualCue: 'Checklist icon' },
        { title: 'Myth 4', body: 'One clear takeaway.', highlight: 'Key idea', visualCue: 'Simple icon' },
        { title: 'Myth 5', body: 'One actionable step.', highlight: 'Tip', visualCue: 'Mini chart' },
        { title: 'Quick recap', body: 'Save this checklist â€¢ Follow PL Capital', highlight: 'Save', visualCue: 'Checklist icons + CTA' }
      ],
      finalSlideCta: 'Save this checklist â€¢ Follow PL Capital',
      disclaimerLine: 'Market risks apply.'
    };

    const groqKey = process.env.GROQ_API_KEY;
    if (!groqKey) {
      return defaults;
    }

    const systemPrompt = `You are an expert at creating carousel post content for financial services (PL Capital). Your output MUST be valid JSON only, no markdown or explanation.

Output a single JSON object with exactly these keys:
- "slideCount": number between 5 and 12 (total slides including cover and final)
- "coverText": string, punchy headline for the cover slide (max 6 words)
- "slides": array of objects. Each object has: "title" (short headline, max 6 words), "body" (1-2 lines, very short), "highlight" (one word or short badge, e.g. "Tip", "Busted"), "visualCue" (short description for the image, e.g. "Simple icon + mini chart"). Length of slides array should equal slideCount (cover = index 0, final = last index). Cover slide: title = coverText, body = "Swipe â†’" or "Swipe â†’\\nSave later" for Instagram. Final slide: CTA and disclaimer.
- "finalSlideCta": string, call-to-action for last slide (e.g. "Save this checklist â€¢ Follow PL Capital")
- "disclaimerLine": string, exact compliance line (e.g. "Market risks apply.")

Rules: No guaranteed returns, no "sure-shot" claims. Professional, compliant, scroll-stopping. Platform: ${platform}.

IMPORTANT â€“ Continuation and theme: The carousel must read as one coherent story. Each slide must logically continue from the previous (same theme, narrative flow, and key points in order). Keep the same brand voice and visual language across all slides so the generated images can share one consistent look (colors, typography, style).`;

    const userPrompt = `Create carousel content for topic: ${topic}
Language: ${language}
Platform: ${platform}
Slides must form a logical sequence: cover â†’ key points in order â†’ final CTA. Same theme and brand tone throughout so visuals stay consistent.
${planningText ? `Optional creative direction from planning:\n${planningText}\n` : ''}
Output ONLY the JSON object, no other text.`;

    try {
      const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
          Authorization: `Bearer ${groqKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: process.env.GROQ_CAROUSEL_MODEL || 'llama-3.3-70b-versatile',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
          ],
          temperature: 0.6,
          max_tokens: 2000
        })
      });

      if (!response.ok) {
        const text = await response.text().catch(() => '');
        console.log(`   âš ï¸ Groq carousel API error: ${response.status} ${text}`);
        return defaults;
      }

      const data = await response.json();
      let raw = (data.choices?.[0]?.message?.content || '').trim();
      raw = raw.replace(/^```(?:json)?\s*|\s*```$/g, '').trim();
      const parsed = JSON.parse(raw);

      const slideCount = Math.min(12, Math.max(5, Number(parsed.slideCount) || 7));
      const coverText = typeof parsed.coverText === 'string' ? parsed.coverText.trim() : defaults.coverText;
      const slides = Array.isArray(parsed.slides) ? parsed.slides.slice(0, slideCount) : defaults.slides;
      const finalSlideCta = typeof parsed.finalSlideCta === 'string' ? parsed.finalSlideCta.trim() : defaults.finalSlideCta;
      const disclaimerLine = typeof parsed.disclaimerLine === 'string' ? parsed.disclaimerLine.trim() : defaults.disclaimerLine;

      const normalizedSlides = slides.map((s, i) => ({
        title: typeof s?.title === 'string' ? s.title.trim() : (i === 0 ? coverText : `Point ${i + 1}`),
        body: typeof s?.body === 'string' ? s.body.trim() : 'One clear takeaway.',
        highlight: typeof s?.highlight === 'string' ? s.highlight.trim() : 'Key idea',
        visualCue: typeof s?.visualCue === 'string' ? s.visualCue.trim() : 'Simple icon + mini chart'
      }));
      while (normalizedSlides.length < slideCount) {
        normalizedSlides.push({
          title: `Point ${normalizedSlides.length + 1}`,
          body: 'One clear takeaway.',
          highlight: 'Key idea',
          visualCue: 'Simple icon + mini chart'
        });
      }

      return {
        slideCount,
        coverText,
        slides: normalizedSlides.slice(0, slideCount),
        finalSlideCta,
        disclaimerLine
      };
    } catch (err) {
      console.log(`   âš ï¸ Carousel content generation failed: ${err instanceof Error ? err.message : 'unknown'}`);
      return defaults;
    }
  }

  /**
   * Initialize the workflow system
   */
  async initialize() {
    console.log('ðŸ“¦ Initializing workflow state...');
    await this.stateManager.initialize();
    console.log('âœ… Workflow state loaded');
  }

  /**
   * Display ASCII banner
   */
  displayBanner() {
    console.log('');
    console.log('â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—');
    console.log('â•‘                                                                   â•‘');
    console.log('â•‘   ðŸš€ SOCIAL MEDIA CAMPAIGN AUTOMATION                             â•‘');
    console.log('â•‘   AI-Powered Multi-Platform Content & Video Production            â•‘');
    console.log('â•‘                                                                   â•‘');
    console.log('â•‘   Platforms: LinkedIn â”‚ Instagram â”‚ YouTube â”‚ Facebook â”‚ Twitter  â•‘');
    console.log('â•‘   Video: Veo 3.1 â”‚ HeyGen â”‚ Shotstack â”‚ Flux                      â•‘');
    console.log('â•‘                                                                   â•‘');
    console.log('â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•');
    console.log('');
  }

  /**
   * Show workflow status
   */
  async showStatus() {
    console.log('\n' + '='.repeat(72));
    console.log('ðŸ“Š SOCIAL MEDIA CAMPAIGN STATUS');
    console.log('='.repeat(72) + '\n');

    const state = this.stateManager.state;

    // Campaigns
    const campaigns = Object.values(state.campaigns || {});
    console.log('ðŸ“‹ CAMPAIGNS:');
    console.log(`   Total: ${campaigns.length}`);

    const byPlatform = {};
    campaigns.forEach(c => {
      byPlatform[c.platform] = (byPlatform[c.platform] || 0) + 1;
    });

    console.log('\n   By Platform:');
    Object.entries(byPlatform).forEach(([platform, count]) => {
      console.log(`   - ${platform.padEnd(15)}: ${count}`);
    });

    // Content pieces
    const content = Object.values(state.content || {});
    console.log(`\nðŸ“ CONTENT PIECES: ${content.length}`);

    const byStatus = {
      draft: content.filter(c => c.status === 'draft').length,
      'ready-for-visual': content.filter(c => c.status === 'ready-for-visual').length,
      'visual-ready': content.filter(c => c.status === 'visual-ready').length,
      'video-ready': content.filter(c => c.status === 'video-ready').length,
      'ready-to-publish': content.filter(c => c.status === 'ready-to-publish').length,
      published: content.filter(c => c.status === 'published').length
    };

    console.log('\n   By Status:');
    Object.entries(byStatus).forEach(([status, count]) => {
      if (count > 0) {
        console.log(`   - ${status.padEnd(20)}: ${count}`);
      }
    });

    // API Configuration
    console.log('\nðŸ”‘ API CONFIGURATION:');
    console.log(`   Groq (Content):    ${process.env.GROQ_API_KEY ? 'âœ…' : 'âŒ'}`);
    console.log(`   HeyGen (Avatar):   ${process.env.HEYGEN_API_KEY ? 'âœ…' : 'âŒ'}`);
    console.log(`   Gemini (VEO):      ${process.env.GEMINI_API_KEY ? 'âœ…' : 'âŒ'}`);
    console.log(`   fal.ai (LongCat):  ${process.env.FAL_KEY ? 'âœ…' : 'âš ï¸  Optional (for videos >148s)'}`);
    console.log(`   Replicate (Flux):  ${process.env.REPLICATE_API_TOKEN ? 'âœ…' : 'âš ï¸  Optional'}`);
    console.log(`   Shotstack (Edit):  ${process.env.SHOTSTACK_API_KEY ? 'âœ…' : 'âš ï¸  Optional'}`);
    console.log(`   ImgBB (Host):      ${process.env.IMGBB_API_KEY ? 'âœ…' : 'âš ï¸  Optional'}`);

    console.log('\n' + '='.repeat(72) + '\n');
  }

  /**
   * Run specific campaign type
   */
  async runCampaign(campaignType, options = {}) {
    const campaignHandlers = {
      'linkedin-carousel': this.runLinkedInCarousel.bind(this),
      'instagram-reel': this.runInstagramReel.bind(this),
      'instagram-carousel': this.runInstagramCarousel.bind(this),
      'youtube-explainer': this.runYouTubeExplainer.bind(this),
      'youtube-short': this.runYouTubeShort.bind(this),
      'facebook-reel': this.runFacebookReel.bind(this),
      'twitter-thread': this.runTwitterThread.bind(this),
      'email-newsletter': this.runEmailNewsletter.bind(this)
    };

    const handler = campaignHandlers[campaignType];
    if (!handler) {
      throw new Error(`Unknown campaign type: ${campaignType}`);
    }

    return await handler(options);
  }

  /**
   * Run specific workflow stage
   */
  async runStage(stageName, options = {}) {
    const stageHandlers = {
      planning: this.stagePlanning.bind(this),
      content: this.stageContent.bind(this),
      visuals: this.stageVisuals.bind(this),
      video: this.stageVideo.bind(this),
      publishing: this.stagePublishing.bind(this),
      tracking: this.stageTracking.bind(this)
    };

    const handler = stageHandlers[stageName];
    if (!handler) {
      throw new Error(`Unknown stage: ${stageName}`);
    }

    return await handler(options);
  }

  /**
   * CAMPAIGN HANDLERS
   */

  async runLinkedInCarousel(options) {
    console.log('ðŸ“Š LinkedIn Carousel Campaign');
    console.log(`   Topic: ${options.topic}`);
    console.log(`   Type: ${options.type || 'myth-busting'}\n`);

    // Stage 1: Generate content
    await this.stageContent({
      platform: 'linkedin',
      format: 'carousel',
      topic: options.topic,
      type: options.type,
      language: options.language
    });

    // Stage 2: Generate images
    await this.stageVisuals({
      platform: 'linkedin',
      format: 'carousel',
      language: options.language
    });

    // Stage 3: Auto-publish if requested
    if (options.autoPublish) {
      await this.stagePublishing({ platform: 'linkedin' });
    }

    console.log('\nâœ… LinkedIn carousel ready!');
  }

  async runLinkedInTestimonial(options) {
    console.log('ðŸŽ¥ LinkedIn Video Testimonial Campaign');
    console.log(`   Topic: ${options.topic}`);
    console.log(`   Duration: ${options.duration}s\n`);

    // Stage 1: Generate script
    await this.stageContent({
      platform: 'linkedin',
      format: 'video-testimonial',
      topic: options.topic,
      duration: options.duration,
      language: options.language
    });

    // Stage 2: Generate video
    await this.stageVideo({
      platform: 'linkedin',
      format: 'testimonial',
      duration: options.duration,
      useVeo: options.useVeo,
      useAvatar: options.useAvatar,
      waitForCompletion: options.waitForCompletion,
      language: options.language,
      aspectRatio: options.aspectRatio
    });

    // Stage 3: Auto-publish if requested
    if (options.autoPublish) {
      await this.stagePublishing({ platform: 'linkedin' });
    }

    console.log('\nâœ… LinkedIn video testimonial ready!');
  }

  async runInstagramReel(options) {
    console.log('ðŸ“± Instagram Reel Campaign');
    console.log(`   Topic: ${options.topic}`);
    console.log(`   Duration: ${options.duration}s\n`);

    // Generate short-form vertical video
    await this.stageContent({
      platform: 'instagram',
      format: 'reel',
      topic: options.topic,
      duration: options.duration,
      language: options.language
    });

    await this.stageVideo({
      platform: 'instagram',
      format: 'reel',
      aspectRatio: options.aspectRatio || '9:16',
      duration: options.duration,
      useVeo: options.useVeo,
      useAvatar: options.useAvatar,
      language: options.language,
      waitForCompletion: options.waitForCompletion
    });

    if (options.autoPublish) {
      await this.stagePublishing({ platform: 'instagram' });
    }

    console.log('\nâœ… Instagram reel ready!');
  }

  async runYouTubeExplainer(options) {
    console.log('ðŸ“º YouTube Explainer Campaign');
    console.log(`   Topic: ${options.topic}`);
    console.log(`   Duration: ${options.duration}s (${Math.floor(options.duration / 60)} min)\n`);

    // Generate long-form educational content
    await this.stageContent({
      platform: 'youtube',
      format: 'explainer',
      topic: options.topic,
      duration: options.duration
    });

    await this.stageVideo({
      platform: 'youtube',
      format: 'explainer',
      aspectRatio: '16:9',
      duration: options.duration,
      useVeo: options.useVeo || (options.duration > 60), // Auto-use Veo for 60s+
      useAvatar: options.useAvatar,
      waitForCompletion: options.waitForCompletion
    });

    if (options.autoPublish) {
      await this.stagePublishing({ platform: 'youtube' });
    }

    console.log('\nâœ… YouTube explainer ready!');
  }

  /**
   * WORKFLOW STAGE IMPLEMENTATIONS
   */

  async stagePlanning(options) {
    console.log('ðŸ“‹ Stage 1: Campaign Planning');
    console.log('   - Generating creative brief and campaign strategy');
    console.log('   - Defining visual guidelines and messaging\n');

    if (this.simulate) {
      console.log('   [SIMULATED] Planning completed');
      return;
    }

    // Generate creative prompt using Groq
    const groqKey = process.env.GROQ_API_KEY;
    if (!groqKey) {
      console.log('   âš ï¸  GROQ_API_KEY not set. Skipping AI creative brief generation.');
      return;
    }

    try {
      console.log('   ðŸ¤– Generating AI creative brief...\n');

      const systemPrompt = `You are a creative director for PL Capital, a financial services company. Generate a comprehensive creative brief for a social media campaign. Format your response in clean, readable markdown with proper headings and bullet points.`;

      const userPrompt = `Generate a creative brief for this campaign:

**Campaign Type:** ${options.campaignType || 'general'}
**Platform:** ${options.platform || 'multi-platform'}
**Topic:** ${options.topic || 'financial services'}
**Target Audience:** ${options.targetAudience || 'investors and wealth builders'}
**Language:** ${this._getLanguageName(options.language || 'english')}

Include:
1. **Campaign Objective** - Clear goal and KPIs
2. **Target Audience** - Demographics and psychographics
3. **Key Messaging** - 3-5 core messages
4. **Visual Guidelines** - Color palette, imagery style, design elements
5. **Tone & Voice** - Communication style
6. **Content Strategy** - Format-specific recommendations
7. **Call to Action** - Primary and secondary CTAs

Make it specific, actionable, and optimized for ${options.platform || 'the platform'}.`;

      const response = await fetch('https://api.groq.com/openai/v1/chat/completions', {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${groqKey}`,
          'Content-Type': 'application/json'
        },
        body: JSON.stringify({
          model: 'llama-3.3-70b-versatile',
          messages: [
            { role: 'system', content: systemPrompt },
            { role: 'user', content: userPrompt }
          ],
          temperature: 0.7,
          max_tokens: 2000
        })
      });

      if (!response.ok) {
        throw new Error(`Groq API error: ${response.status}`);
      }

      const data = await response.json();
      const creativeBrief = data.choices[0]?.message?.content || '';

      if (creativeBrief) {
        console.log('   âœ… Creative Brief Generated:\n');
        console.log(creativeBrief);
        console.log('\n');

        // Save creative brief to state
        const briefId = `brief-${Date.now()}`;
        await this.stateManager.addContent({
          id: briefId,
          type: 'creative-brief',
          topic: options.topic,
          platform: options.platform,
          campaignType: options.campaignType,
          content: creativeBrief,
          status: 'ready'
        });
      }

      return { success: true, creativeBrief };

    } catch (error) {
      console.error(`   âŒ Creative brief generation failed: ${error.message}`);
      return { success: false, error: error.message };
    }
  }

  async stageContent(options) {
    console.log('âœï¸  Stage 2: Content Generation');
    console.log(`   Platform: ${options.platform}`);
    console.log(`   Format: ${options.format}`);
    console.log(`   Topic: ${options.topic}`);
    if (options.language) {
      console.log(`   Language: ${this._getLanguageName(options.language)}`);
    }
    console.log('');

    // Placeholder for content generation
    if (this.simulate) {
      console.log('   [SIMULATED] Content generated');
      return;
    }

    // Check if this is a video format
    const isVideoFormat = options.format && (
      options.format.includes('video') ||
      options.format.includes('testimonial') ||
      options.format.includes('reel') ||
      options.format.includes('explainer') ||
      options.format.includes('short')
    );

    // For video campaigns, Stage 2 content is optional (creative prompt from Stage 1 is used)
    if (isVideoFormat) {
      console.log('   ðŸŽ¬ Video content format detected');
      console.log('   â„¹ï¸  Using creative prompt from Stage 1 for video generation');
      console.log('   âœ… Proceeding to video production stage');
      return {
        success: true,
        contentType: 'video-script',
        message: 'Video format - using creative prompt for generation'
      };
    }

    // For WhatsApp static creative, delegate to visual generation now
    const isWhatsAppImage = (options.platform && options.platform.includes('whatsapp')) ||
      (options.type && options.type.includes('whatsapp')) ||
      options.format === 'whatsapp' ||
      options.format === 'image';

    if (isWhatsAppImage) {
      console.log('   ðŸ“· Generating WhatsApp static creative with Gemini 3 Pro Image Preview...');
      let prompt = options.prompt || null;
      if (!prompt) {
        await this.stateManager.initialize();
        const planning = this._getLatestCampaignPlanningEntry(options.topic);
        const creativePrompt = (planning?.creativePrompt || planning?.output || '').trim();
        const directPrompt = creativePrompt ? this._extractDirectImagePrompt(creativePrompt) : null;
        if (directPrompt) {
          prompt = directPrompt;
          console.log('   ðŸ“‹ Using Direct image prompt from Stage 1 planning');
        } else if (creativePrompt) {
          console.log('   âš ï¸ Stage 1 creative prompt found but no "Direct image prompt" paragraph; using fallback.');
        } else {
          console.log('   âš ï¸ No Stage 1 planning found for topic; using fallback prompt.');
        }
      }
      if (!prompt) {
        prompt = this._buildVisualPrompt({
          platform: 'whatsapp',
          format: 'image',
          topic: options.topic,
          type: options.type,
          brandSettings: options.brandSettings
        });
      }

      // If a reference image path is provided (via env), use edit mode
      const referenceImagePath = process.env.REFERENCE_IMAGE_PATH;
      const referenceImageUrl = process.env.VISUAL_REFERENCE_URL;
      if (referenceImagePath || referenceImageUrl) {
        console.log(`   ðŸ–¼ï¸  Applying reference image: ${referenceImagePath || referenceImageUrl}`);
      }

      const visualsOptions = {
        platform: 'whatsapp',
        format: 'image',
        topic: options.topic,
        type: options.type,
        prompt,
        aspectRatio: options.aspectRatio,  // Pass aspectRatio from options
        language: options.language  // Pass language from options
      };

      let result;
      if (referenceImagePath || referenceImageUrl) {
        // Use editImage to guide generation with reference
        const generator = new ImageGenerator({
          apiKey: process.env.GEMINI_API_KEY,
          provider: 'gemini'
        });

        const refInput = referenceImagePath || referenceImageUrl;

        const editResult = await generator.editImage(prompt, refInput, {
          aspectRatio: options.aspectRatio || this._getAspectRatioForFormat('story'), // Use provided aspectRatio or default to 9:16 for WhatsApp
          language: options.language  // Pass language for text generation
        });
        result = {
          success: true,
          images: editResult.images || editResult.result || []
        };
      } else {
        result = await this.stageVisuals(visualsOptions);
      }

      if (result?.success) {
        let hostedUrl = null;

        // Attempt to upload the first generated image to ImgBB for a shareable URL
        if (process.env.IMGBB_API_KEY && result.images && result.images.length > 0) {
          const firstImage = result.images[0];
          const imagePath = firstImage.path || firstImage.url;

          if (imagePath && fs.existsSync(imagePath)) {
            try {
              console.log('   â˜ï¸  Uploading WhatsApp creative to ImgBB...');
              const imgBuffer = fs.readFileSync(imagePath);
              const b64 = imgBuffer.toString('base64');
              const payload = new URLSearchParams();
              payload.append('key', process.env.IMGBB_API_KEY);
              payload.append('image', b64);

              const uploadResp = await fetch('https://api.imgbb.com/1/upload', {
                method: 'POST',
                headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
                body: payload
              });

              if (uploadResp.ok) {
                const json = await uploadResp.json();
                hostedUrl = json?.data?.url || null;
                if (hostedUrl) {
                  console.log(`   âœ… Uploaded to ImgBB: ${hostedUrl}`);
                  // persist URL back into result
                  result.images[0].hostedUrl = hostedUrl;
                }
              } else {
                const text = await uploadResp.text();
                console.log(`   âš ï¸ ImgBB upload failed: ${uploadResp.status} ${text}`);
              }
            } catch (err) {
              console.log(`   âš ï¸ ImgBB upload error: ${err instanceof Error ? err.message : 'unknown'}`);
            }
          }
        } else {
          console.log('   â„¹ï¸  ImgBB upload skipped (no API key or image path missing)');
        }

        console.log('   âœ… WhatsApp creative generated');
        return result;
      }

      console.log('   âš ï¸ WhatsApp creative generation failed or returned no result');
      return;
    }

    // Carousel (LinkedIn/Instagram): generate slide structure and save to state for Stage 3
    const isCarousel = options.format === 'carousel' && (options.platform === 'linkedin' || options.platform === 'instagram');
    if (isCarousel) {
      const carouselPlatform = options.platform;
      const platformLabel = carouselPlatform === 'instagram' ? 'Instagram' : 'LinkedIn';
      console.log(`   ðŸ§© Generating ${platformLabel} carousel content (slides + copy)...`);

      const carousel = await this._generateCarouselContent({
        topic: options.topic,
        platform: carouselPlatform,
        language: options.language
      });

      const contentPack = {
        platforms: {
          [carouselPlatform]: {
            carousel: {
              slideCount: carousel.slideCount,
              coverText: carousel.coverText,
              slides: carousel.slides,
              finalSlideCta: carousel.finalSlideCta,
              disclaimerLine: carousel.disclaimerLine
            }
          }
        }
      };

      const contentId = `CONT-carousel-${Date.now()}`;
      await this.stateManager.addContent({
        id: contentId,
        topic: (options.topic || '').trim() || 'Carousel',
        contentPack,
        status: 'completed',
        completedAt: new Date().toISOString()
      });

      console.log(`   âœ… Carousel content saved (${carousel.slideCount} slides) â€” ready for Stage 3 visuals`);
      return {
        success: true,
        contentId,
        slideCount: carousel.slideCount,
        coverText: carousel.coverText,
        message: `${platformLabel} carousel content generated`
      };
    }

    // Twitter/X thread: generate tweet list and save (text-only, no Stage 3 visuals)
    const isThreadContent = options.format === 'thread' && options.platform === 'twitter';
    if (isThreadContent) {
      console.log('   ðŸ§µ Generating Twitter/X thread content (tweets)...');

      const thread = await this._generateThreadContent({
        topic: options.topic,
        language: options.language
      });

      const contentPack = {
        platforms: {
          twitter: {
            thread: {
              tweets: thread.tweets
            }
          }
        }
      };

      const contentId = `CONT-thread-${Date.now()}`;
      await this.stateManager.addContent({
        id: contentId,
        topic: (options.topic || '').trim() || 'Twitter Thread',
        contentPack,
        status: 'completed',
        completedAt: new Date().toISOString()
      });

      console.log(`   âœ… Thread content saved (${thread.tweets.length} tweets) â€” ready to copy or publish`);
      return {
        success: true,
        contentId,
        tweetCount: thread.tweets.length,
        tweets: thread.tweets,
        message: 'Twitter/X thread content generated'
      };
    }

    // TODO: Implement other AI content generation
    console.log('   âš ï¸  Content generation not yet implemented for this platform');
  }

  async stageVisuals(options) {
    console.log('ðŸŽ¨ Stage 3: Visual Asset Production');
    console.log(`   Platform: ${options.platform}`);
    if (options.language) {
      console.log(`   Language: ${this._getLanguageName(options.language)}`);
    }
    console.log(`   Format: ${options.format}`);

    // Check if this is a video-only format (skip image generation for faceless videos)
    const isVideoOnlyFormat = options.format && (
      options.format.includes('video') ||
      options.format.includes('testimonial') ||
      options.format.includes('reel') ||
      options.format.includes('explainer') ||
      options.format.includes('short')
    );

    if (isVideoOnlyFormat) {
      console.log('   ðŸŽ¬ Video-only format detected (faceless video)');
      console.log('   â­ï¸  Skipping image generation - proceeding directly to video production');
      return {
        success: true,
        skipped: true,
        reason: 'Video-only campaign - no static images needed'
      };
    }

    console.log(`   Model: Gemini 3 Pro Image Preview (4K, Grounded)\n`);

    // Placeholder for visual generation
    if (this.simulate) {
      console.log('   [SIMULATED] Visuals generated');
      return { success: true, simulated: true };
    }

    // Check for API key
    if (!process.env.GEMINI_API_KEY) {
      console.log('   âš ï¸  GEMINI_API_KEY not set. Set it with: export GEMINI_API_KEY="your-key"');
      return { success: false, error: 'Missing GEMINI_API_KEY' };
    }

    try {
      // Initialize ImageGenerator with Gemini 3 Pro as primary
      const generator = new ImageGenerator({
        apiKey: process.env.GEMINI_API_KEY,
        provider: 'gemini'
      });

      const uploadToImgBB = async (imagePath) => {
        if (!process.env.IMGBB_API_KEY) return null;
        if (!imagePath || !fs.existsSync(imagePath)) return null;
        try {
          const imgBuffer = fs.readFileSync(imagePath);
          const b64 = imgBuffer.toString('base64');
          const payload = new URLSearchParams();
          payload.append('key', process.env.IMGBB_API_KEY);
          payload.append('image', b64);
          const uploadResp = await fetch('https://api.imgbb.com/1/upload', {
            method: 'POST',
            headers: { 'Content-Type': 'application/x-www-form-urlencoded' },
            body: payload
          });
          if (!uploadResp.ok) {
            const text = await uploadResp.text().catch(() => '');
            console.log(`   âš ï¸ ImgBB upload failed: ${uploadResp.status} ${text}`);
            return null;
          }
          const json = await uploadResp.json();
          return json?.data?.url || null;
        } catch (err) {
          console.log(`   âš ï¸ ImgBB upload error: ${err instanceof Error ? err.message : 'unknown'}`);
          return null;
        }
      };

      // Carousel (LinkedIn/Instagram): generate one image per slide, then upload each to ImgBB
      const isCarousel = options.format === 'carousel' && (options.platform === 'linkedin' || options.platform === 'instagram');
      if (isCarousel) {
        const carouselPlatform = options.platform;
        const platformLabel = carouselPlatform === 'instagram' ? 'Instagram' : 'LinkedIn';
        console.log(`   ðŸ§© ${platformLabel} carousel detected â€” generating slide images...`);

        const contentEntries = Object.values(this.stateManager?.state?.content || {}).filter(Boolean);
        const byCompletedAtDesc = (a, b) => {
          const aTs = new Date(a?.completedAt || a?.updatedAt || a?.createdAt || 0).getTime();
          const bTs = new Date(b?.completedAt || b?.updatedAt || b?.createdAt || 0).getTime();
          return bTs - aTs;
        };
        const topic = (options.topic || '').trim();
        const withCarousel = contentEntries.filter((e) => e?.contentPack?.platforms?.[carouselPlatform]?.carousel);
        const latestContent =
          (withCarousel.length > 0
            ? (topic ? withCarousel.filter((e) => (e?.topic || '').trim() === topic).sort(byCompletedAtDesc)[0] : null) || withCarousel.sort(byCompletedAtDesc)[0]
            : null) || (topic ? contentEntries.filter((e) => (e?.topic || '').trim() === topic).sort(byCompletedAtDesc)[0] : null) || contentEntries.sort(byCompletedAtDesc)[0] || null;

        const carousel = latestContent?.contentPack?.platforms?.[carouselPlatform]?.carousel || null;
        const slideCount = Math.min(12, Math.max(5, Number(carousel?.slideCount || 7)));
        const coverText = carousel?.coverText || options.topic || 'Quick Investing Checklist';
        const slides = Array.isArray(carousel?.slides) ? carousel.slides : [];
        const finalSlideCta = carousel?.finalSlideCta || 'Save this checklist â€¢ Follow PL Capital';
        const disclaimerLine = carousel?.disclaimerLine || 'Market risks apply.';

        const clampWords = (text, maxWords) => {
          const words = String(text || '').trim().split(/\s+/).filter(Boolean);
          if (words.length <= maxWords) return text;
          return words.slice(0, maxWords).join(' ');
        };
        const clampLines = (text, maxLines, maxCharsPerLine) => {
          const raw = String(text || '').trim();
          const lines = raw.split(/\r?\n/).map((l) => l.trim()).filter(Boolean);
          const limited = (lines.length ? lines : [raw]).slice(0, maxLines).map((l) => l.length <= maxCharsPerLine ? l : `${l.slice(0, maxCharsPerLine - 1).trim()}â€¦`);
          return limited.join('\n');
        };

        const resolvedSlides = Array.from({ length: slideCount }).map((_, idx) => {
          const s = slides[idx] || {};
          const isCover = idx === 0;
          const isFinal = idx === slideCount - 1;
          if (isCover) return { title: coverText, body: s.body || 'Swipe â†’', highlight: s.highlight || 'Checklist', visualCue: s.visualCue || 'Bold cover headline, minimal icons' };
          if (isFinal) return { title: s.title || 'Quick recap', body: s.body || `${finalSlideCta}\n${disclaimerLine}`, highlight: s.highlight || 'Save', visualCue: s.visualCue || 'Checklist icons + CTA' };
          return { title: s.title || `Point ${idx}`, body: s.body || 'One clear takeaway.', highlight: s.highlight || 'Key idea', visualCue: s.visualCue || 'Simple icon + mini chart' };
        });

        const brandStyle = 'PL Capital brand: Navy (#0e0e6a), Blue (#3c3cf8), Teal (#00d084), Green (#66e766), Figtree typography. Professional, clean, no exaggerated claims.';
        const generatedImages = [];
        for (let i = 0; i < resolvedSlides.length; i++) {
          const slide = resolvedSlides[i];
          const slideNumber = i + 1;
          const total = resolvedSlides.length;
          const maxBodyChars = carouselPlatform === 'instagram' ? 32 : 40;
          const safeTitle = clampWords(slide.title, 6);
          const safeBody = clampLines(slide.body, 2, maxBodyChars);
          const safeHighlight = clampLines(slide.highlight, 1, 18);
          const safeVisualCue = clampLines(slide.visualCue, 2, 60);
          const platformLabel = carouselPlatform === 'instagram' ? 'Instagram' : 'LinkedIn';

          if (i === 0) {
            const slidePrompt = carouselPlatform === 'instagram'
              ? `Design ONE Instagram carousel slide (1:1) for PL Capital (India, finance). Slide ${slideNumber}/${total}. Headline: ${safeTitle}. Body: ${safeBody}. Highlight: ${safeHighlight}. Visual: ${safeVisualCue}. ${brandStyle}`
              : `Design ONE LinkedIn carousel slide (1:1) for PL Capital (India, finance). Slide ${slideNumber}/${total}. Headline: ${safeTitle}. Body: ${safeBody}. Highlight: ${safeHighlight}. Visual: ${safeVisualCue}. ${brandStyle}`;

            console.log(`   â³ Generating carousel slide ${slideNumber}/${total} (first slide)...`);
            const slideResult = await generator.generateSocialGraphic(slidePrompt, carouselPlatform, {
              imageSize: '4K',
              useGrounding: false,
              aspectRatio: '1:1',
              language: options.language,
              numberOfImages: 1
            });
            const first = slideResult?.images?.[0];
            if (first) {
              generatedImages.push(first);
              console.log(`   âœ… Slide ${slideNumber} generated: ${first.path || first.url || 'success'}`);
            }
          } else {
            const prevImage = generatedImages[i - 1];
            const prevPath = prevImage?.path || prevImage?.url;
            if (!prevPath) {
              console.log(`   âš ï¸ No previous slide image; generating slide ${slideNumber} standalone.`);
              const fallbackPrompt = carouselPlatform === 'instagram'
                ? `Design ONE Instagram carousel slide (1:1) for PL Capital (India, finance). Slide ${slideNumber}/${total}. Headline: ${safeTitle}. Body: ${safeBody}. Highlight: ${safeHighlight}. Visual: ${safeVisualCue}. ${brandStyle}`
                : `Design ONE LinkedIn carousel slide (1:1) for PL Capital (India, finance). Slide ${slideNumber}/${total}. Headline: ${safeTitle}. Body: ${safeBody}. Highlight: ${safeHighlight}. Visual: ${safeVisualCue}. ${brandStyle}`;
              const fallbackResult = await generator.generateSocialGraphic(fallbackPrompt, carouselPlatform, {
                imageSize: '4K',
                useGrounding: false,
                aspectRatio: '1:1',
                language: options.language,
                numberOfImages: 1
              });
              const first = fallbackResult?.images?.[0];
              if (first) generatedImages.push(first);
              continue;
            }

            const continuationPrompt = `Create the NEXT ${platformLabel} carousel slide (1:1). Match the exact visual style, color palette, typography, and brand look of the reference image (same PL Capital branding). This is slide ${slideNumber} of ${total}. New content for THIS slide only: Headline: "${safeTitle}". Body: "${safeBody}". Highlight: "${safeHighlight}". Visual: ${safeVisualCue}. Do not copy the reference image; create a new slide that continues the carousel with the same theme and brand guidelines.`;

            console.log(`   â³ Generating carousel slide ${slideNumber}/${total} (continuation from previous)...`);
            let editResult;
            try {
              editResult = await generator.editImage(continuationPrompt, prevPath, {
                aspectRatio: '1:1',
                imageSize: '4K',
                useGrounding: false,
                language: options.language
              });
            } catch (err) {
              console.log(`   âš ï¸ Continuation edit failed for slide ${slideNumber}, generating standalone: ${err.message}`);
              const fallbackPrompt = carouselPlatform === 'instagram'
                ? `Design ONE Instagram carousel slide (1:1) for PL Capital (India, finance). Slide ${slideNumber}/${total}. Headline: ${safeTitle}. Body: ${safeBody}. Highlight: ${safeHighlight}. Visual: ${safeVisualCue}. ${brandStyle}`
                : `Design ONE LinkedIn carousel slide (1:1) for PL Capital (India, finance). Slide ${slideNumber}/${total}. Headline: ${safeTitle}. Body: ${safeBody}. Highlight: ${safeHighlight}. Visual: ${safeVisualCue}. ${brandStyle}`;
              const fallbackResult = await generator.generateSocialGraphic(fallbackPrompt, carouselPlatform, {
                imageSize: '4K',
                useGrounding: false,
                aspectRatio: '1:1',
                language: options.language,
                numberOfImages: 1
              });
              const first = fallbackResult?.images?.[0];
              if (first) generatedImages.push(first);
              continue;
            }
            const first = editResult?.images?.[0];
            if (first) {
              generatedImages.push(first);
              console.log(`   âœ… Slide ${slideNumber} generated (continuation): ${first.path || first.url || 'success'}`);
            }
          }
        }

        if (process.env.IMGBB_API_KEY && generatedImages.length > 0) {
          console.log('   â˜ï¸  Uploading carousel slides to ImgBB...');
          for (const img of generatedImages) {
            const imagePath = img.path || img.url;
            const hostedUrl = await uploadToImgBB(imagePath);
            if (hostedUrl) {
              img.hostedUrl = hostedUrl;
              console.log(`   âœ… Uploaded to ImgBB: ${hostedUrl}`);
            }
          }
        } else {
          console.log('   â„¹ï¸  ImgBB upload skipped (no API key or no images)');
        }

        return {
          success: true,
          images: generatedImages,
          features: ['carousel', 'multi-slide']
        };
      }

      // Single image (non-carousel): generate one visual, then upload to ImgBB
      const prompt = options.prompt || this._buildVisualPrompt(options);
      console.log(`   Prompt: ${prompt.substring(0, 80)}...`);
      console.log('   â³ Generating image (Gemini 3 Pro, 4K)...\n');

      const result = await generator.generateSocialGraphic(prompt, options.platform, {
        imageSize: '4K',
        useGrounding: true,
        aspectRatio: options.aspectRatio || this._getAspectRatioForFormat(options.format),
        language: options.language  // Pass language for text generation
      });

      console.log(`   âœ… Visual generated: ${result.images[0]?.path || 'success'}`);
      console.log(`   Features: ${result.features?.join(', ') || 'N/A'}`);

      if (process.env.IMGBB_API_KEY && result.images && result.images.length > 0) {
        console.log('   â˜ï¸  Uploading visual(s) to ImgBB...');
        for (const img of result.images) {
          const imagePath = img.path || img.url;
          const hostedUrl = await uploadToImgBB(imagePath);
          if (hostedUrl) {
            img.hostedUrl = hostedUrl;
            console.log(`   âœ… Uploaded to ImgBB: ${hostedUrl}`);
          }
        }
      } else {
        console.log('   â„¹ï¸  ImgBB upload skipped (no API key or no images)');
      }

      return {
        success: true,
        images: result.images,
        features: result.features
      };
    } catch (error) {
      console.error(`   âŒ Visual generation failed: ${error.message}`);
      return { success: false, error: error.message };
    }
  }

  /**
   * Get language name from language code
   */
  _getLanguageName(languageCode) {
    const languageMap = {
      'english': 'English',
      'hindi': 'Hindi',
      'bengali': 'Bengali',
      'telugu': 'Telugu',
      'marathi': 'Marathi',
      'tamil': 'Tamil',
      'gujarati': 'Gujarati',
      'kannada': 'Kannada',
      'malayalam': 'Malayalam',
      'punjabi': 'Punjabi',
      'urdu': 'Urdu',
      'odia': 'Odia',
      'assamese': 'Assamese'
    };
    return languageMap[languageCode] || 'English';
  }

  /**
   * Build visual prompt based on options
   */
  _buildVisualPrompt(options) {
    const { platform, format, topic, type, brandSettings, language = 'english', whatsapp } = options;
    const languageName = this._getLanguageName(language);

    const defaultBrand = 'PL Capital brand palette: Navy (#0e0e6a), Blue (#3c3cf8), Teal (#00d084), Green (#66e766); typography: Figtree; tone: professional, trustworthy, data-driven.';
    const customBrandColors = brandSettings?.customColors
      ? `Brand colors: ${brandSettings.customColors}.`
      : '';
    const brandTone = brandSettings?.customTone
      ? `Tone: ${brandSettings.customTone}.`
      : '';
    const brandInstructions = brandSettings?.customInstructions
      ? `Additional guidance: ${brandSettings.customInstructions}.`
      : '';
    const brandGuidance = brandSettings
      ? `${customBrandColors} ${brandTone} ${brandInstructions}`.trim() || defaultBrand
      : defaultBrand;

    const safeFormat = format || 'image';

    const languageInstruction = language !== 'english'
      ? ` All text, labels, and content must be in ${languageName}.`
      : '';

    const exampleStyle = 'Style reference: PL Capital example creatives with high-contrast navy/blue gradient background, modern geometric shapes (blue/green accents), big bold white headline, 2â€“4 supporting bullets with checkmark icons OR a simple numbered step row, and a single green rounded CTA button. Clean whitespace, crisp typography (Figtree-like), modern corporate aesthetic.';
    const noLogo = 'Do NOT add any logo/watermark/brand mark. If branding is needed later, reserve clean empty space in the top-right.';

    const basePrompts = {
      linkedin: `Professional ${safeFormat} graphic for LinkedIn about ${topic || 'financial investment'}. ${exampleStyle} ${noLogo} ${brandGuidance}${languageInstruction}`,
      instagram: `Eye-catching ${safeFormat} visual for Instagram about ${topic || 'investment growth'}. ${exampleStyle} ${noLogo} ${brandGuidance}${languageInstruction}`,
      youtube: `High-quality ${safeFormat} thumbnail/graphic for YouTube about ${topic || 'wealth building'}. Bold text, high contrast, attention-grabbing design. ${exampleStyle} ${noLogo} ${brandGuidance}${languageInstruction}`,
      facebook: `Engaging ${safeFormat} post graphic for Facebook about ${topic || 'financial planning'}. Clear, friendly messaging with strong hierarchy. ${exampleStyle} ${noLogo} ${brandGuidance}${languageInstruction}`,
      twitter: `Concise ${safeFormat} visual for Twitter about ${topic || 'market insights'}. Minimal but high-contrast layout optimized for quick scan. ${exampleStyle} ${noLogo} ${brandGuidance}${languageInstruction}`,
      whatsapp: (() => {
        const headline = whatsapp?.headline ? String(whatsapp.headline).trim() : '';
        const body = whatsapp?.body ? String(whatsapp.body).trim() : '';
        const cta = whatsapp?.cta ? String(whatsapp.cta).trim() : '';

        const contentSpec = (headline || body || cta)
          ? `Text to render (exact):
Headline: ${headline || (topic || 'Your offer')}
Body: ${body || 'One clear benefit.\nOne clear next step.'}
CTA: ${cta || 'Learn more'}`
          : `Text-forward layout with a bold headline and a single CTA.`;

        return `Design a visually stunning, premium WhatsApp creative poster for PL Capital (India, finance).
Format: 1080x1920 (9:16). Mobile-first readability. High-contrast. Modern and clean.
Goal: instantly communicate the message + drive action (tap/click/forward).

Layout system (STRICT):
- Safe margins: 80px on all sides. Keep all text inside safe area.
- Hierarchy: (1) Headline (2) Body (3) CTA button (4) Small disclaimer footer.
- Headline: big, bold, max 2 lines, 28â€“44 chars/line.
- Body: max 2 lines, 28â€“40 chars/line, supportive and clear.
- CTA: button pill with solid fill (#00b34e / #66e766), white text, 2â€“4 words.
- Footer: tiny disclaimer line (e.g., "Market risks apply.") in 10â€“12px.
- Optional: small icon/illustration on the side (simple, not cluttered).

Brand & style:
- Use PL palette (navy/blue base with green accents). Use Figtree-like sans font.
- Add subtle gradients/texture, but keep background clean (no noisy patterns).
- Use ONE highlight element (badge/chip) to emphasize a key term/number if present.
- No stock-photo faces; avoid busy scenes. Prefer abstract finance motifs (â‚¹, chart line, calendar, shield/trust icon).

Copy accuracy (VERY IMPORTANT):
${contentSpec}

Compliance constraints:
- No guaranteed returns, no "sure-shot", no exaggerated claims.
${languageInstruction}
${brandGuidance}`;
      })()
    };

    return basePrompts[platform] || basePrompts.linkedin;
  }

  /**
   * Get optimal aspect ratio for content format
   */
  _getAspectRatioForFormat(format) {
    const aspectRatios = {
      'carousel': '1:1',
      'post': '1:1',
      'story': '9:16',
      'reel': '9:16',
      'thumbnail': '16:9',
      'explainer': '16:9',
      'cover': '16:9'
    };

    return aspectRatios[format] || '1:1';
  }

  async stageVideo(options) {
    console.log('ðŸŽ¥ Stage 4: Video Production');
    console.log(`   Platform: ${options.platform}`);
    console.log(`   Duration: ${options.duration}s`);
    console.log(`   Aspect Ratio: ${options.aspectRatio || '16:9'}`);
    if (options.language) {
      console.log(`   Language: ${this._getLanguageName(options.language)}`);
    }
    console.log(`   Method: ${options.useVeo ? 'Veo 3.1' : 'Auto-detect'} ${options.useAvatar ? '+ Avatar' : ''}\n`);

    if (this.simulate) {
      console.log('   [SIMULATED] Video generated');
      return { success: true, simulated: true };
    }

    // Check for LongCat configuration from environment variables
    const useLongCat = process.env.LONGCAT_ENABLED === 'true';
    const longCatMode = process.env.LONGCAT_MODE || 'text-to-video';
    const longCatPrompt = process.env.LONGCAT_PROMPT || '';

    try {
      // Initialize video coordinator
      const coordinator = new VideoCoordinator({
        simulate: this.simulate,
        outputDir: path.join(this.projectRoot, 'output', 'videos')
      });

      // Check for custom JSON prompt from environment or options
      const customPromptJson = process.env.VIDEO_PROMPT_JSON || options.videoPromptJson;
      let prompt;
      let scenePrompts = null;
      let promptData = null;

      if (customPromptJson) {
        try {
          promptData = typeof customPromptJson === 'string'
            ? JSON.parse(customPromptJson)
            : customPromptJson;

          // Extract scene prompts if motion timeline exists
          if (promptData.motion && typeof promptData.motion === 'object') {
            scenePrompts = this._extractScenePromptsFromJson(promptData);
            console.log(`   ðŸŽ¬ Detected ${scenePrompts.length} scene prompts from motion timeline`);
          }

          prompt = this._buildPromptFromJson(promptData);
          console.log('   ðŸ“‹ Using custom JSON prompt structure');
        } catch (error) {
          console.log(`   âš ï¸  Invalid JSON prompt, falling back to default: ${error.message}`);
          prompt = longCatPrompt || this._buildVideoPrompt(options);
        }
      } else {
        prompt = longCatPrompt || this._buildVideoPrompt(options);
      }

      const requestedDuration = options.duration || 90;

      // Check if this is avatar mode (VEO-based avatar generation)
      const isAvatarMode = options.useAvatar === true;
      const looksLikeHeyGenAvatarId = (value) =>
        typeof value === 'string' && /^[a-f0-9]{32}$/i.test(value.trim());

      const isHeyGenAvatar =
        options.avatarId === 'siddharth-vora' ||
        looksLikeHeyGenAvatarId(options.avatarId) ||
        Boolean(options.heygenAvatarGroupId) ||
        Boolean(options.heygenAvatarId);

      // For avatar mode (non-HeyGen), augment prompt with avatar and voice descriptions
      if (isAvatarMode && !isHeyGenAvatar) {
        console.log('   ðŸŽ­ Avatar mode detected (VEO-based)');

        // Male/female from avatarId (generic-indian-male / generic-indian-female) or options
        const isFemale = options.avatarGender === 'female' || (options.avatarId && String(options.avatarId).toLowerCase().includes('female'));
        const genderTerm = isFemale ? 'female' : 'male';
        const voiceGender = isFemale ? 'Confident Indian female voice, clear articulation, professional tone' : 'Deep, confident Indian male voice with slight accent, clear articulation';

        const skinRealism = 'Hyperrealistic, photorealistic skin with visible pores, subtle skin texture and natural blemishes; no smooth or plastic AI skin; documentary-style realism.';
        const avatarDescription = options.avatarDescription || `Indian ${genderTerm} professional in formal business attire, confident posture, warm expression. ${skinRealism}`;
        const voiceDescription = options.voiceDescription || voiceGender;

        // Auto-generate script instruction if not provided (frontend sends avatarScriptText)
        const userScript = options.scriptText || options.avatarScriptText;
        let scriptInstruction;
        if (userScript) {
          scriptInstruction = `speaking the following script: "${userScript}"`;
          console.log(`   ðŸ“ Script: ${userScript.substring(0, 60)}...`);
        } else {
          // Generate script instruction based on platform and topic
          const topic = options.topic || 'financial services and investment opportunities';
          const platform = options.platform || 'linkedin';
          const format = options.format || 'testimonial';

          const languageName = this._getLanguageName(options.language || 'english');
          const languageInstruction = options.language && options.language !== 'english'
            ? ` All speech and dialogue must be in ${languageName}.`
            : '';
          scriptInstruction = `delivering a professional ${format} about ${topic} for ${platform}. Generate natural, engaging speech that is informative, trustworthy, and appropriate for the platform. Include key points, benefits, and a clear message. Speech should be conversational yet professional, matching Indian business communication style.${languageInstruction}`;

          console.log(`   ðŸ“ Script: [Auto-generated for ${topic}]`);
        }

        console.log(`   ðŸ‘¤ Avatar: ${avatarDescription}`);
        console.log(`   ðŸŽ™ï¸  Voice: ${voiceDescription}`);

        // Viral reel optimization for Instagram Reels / Facebook Reels / YouTube Shorts
        const isReelOrShort = options.platform === 'instagram' || options.platform === 'facebook' || options.platform === 'youtube' || /reel|short/i.test(options.format || '') || /youtube-short/i.test(options.type || '');
        const viralGuidance = isReelOrShort
          ? ' Pacing: viral reel style â€” strong visual hook in the first 1â€“2 seconds (avatar catches attention immediately), punchy delivery, ending that feels loopable. Include a clear on-screen CTA moment (e.g. "Save this", "Follow for more").'
          : '';

        // Veo 3.1 best practices for avatar: [Cinematography] + [Subject] + [Action] + [Context] + [Style & Ambiance]. Do not append faceless base prompt.
        const topicContext = options.topic ? ` Topic/context: ${options.topic}.` : '';
        const avatarPrompt = `Professional video featuring ${avatarDescription}. ${voiceDescription} ${scriptInstruction}. Camera: Medium shot, professional framing, slight depth of field. Lighting: Soft key light, professional studio setup with subtle rim lighting. Skin: hyperrealistic, natural pores and subtle texture, avoid smooth plastic AI skin. Background: Elegant office environment with soft bokeh, professional corporate setting.${viralGuidance}${topicContext}`;

        prompt = avatarPrompt;
        console.log('   âœ… Avatar prompt constructed\n');
      }

      // HeyGen avatar routing (Siddharth Vora + other avatars from /api/avatars mapping)
      if (isAvatarMode && isHeyGenAvatar) {
        const prettyAvatarId = (value) => {
          if (!value) return '';
          const s = String(value).trim();
          return s.length > 12 ? `${s.slice(0, 8)}â€¦` : s;
        };

        const avatarDisplayName =
          options.avatarId === 'siddharth-vora'
            ? 'Siddharth Vora (Custom)'
            : `HeyGen Avatar (${prettyAvatarId(options.avatarId || options.heygenAvatarId)})`;

        console.log('\nðŸŽ¬ HeyGen Avatar Mode');
        console.log(`   Provider: HeyGen`);
        console.log(`   Avatar: ${avatarDisplayName}`);
        console.log(`   Duration: ${requestedDuration}s\n`);

        // Check for HeyGen API key
        if (!process.env.HEYGEN_API_KEY) {
          throw new Error('HEYGEN_API_KEY environment variable is required for HeyGen avatar generation');
        }

        // Generate or use script (frontend sends avatarScriptText; CLI may send scriptText)
        const userScript = options.scriptText || options.avatarScriptText;
        let scriptText;
        if (userScript) {
          scriptText = userScript;
          console.log(`   ðŸ“ Script: ${scriptText.substring(0, 60)}...`);
        } else {
          try {
            scriptText = await this._generateHeyGenScript({
              topic: options.topic,
              platform: options.platform,
              format: options.format,
              duration: requestedDuration,
              language: options.language
            });
          } catch (error) {
            console.log(`   âš ï¸  Script generation failed; using fallback: ${error.message}`);
            const topic = options.topic || 'PL Capital investing insights';
            scriptText = `Hi, quick update from PL Capital. ${topic}. If you want a portfolio review or a plan, talk to us today. Market risks apply.`;
          }
          console.log(`   ðŸ“ Script: ${scriptText.substring(0, 60)}...`);
        }

        // Avatar/voice resolution aligned with martech (multiple HeyGen avatars + mapped voices)
        // - Siddharth Vora: env or hardcoded Siddharth defaults
        // - Other HeyGen avatars (32-char groupId): options.avatarId + options.avatarVoiceId or voice from mapping
        const SIDDHARTH_AVATAR_ID = '9da4afb2c22441b5aab73369dda7f65d';
        const SIDDHARTH_VOICE_ID = 'c8d184ef4d81484a97d70c94bb76fec3';
        const isSiddharthVora = options.avatarId === 'siddharth-vora';
        const isGroupIdAvatar = looksLikeHeyGenAvatarId(options.avatarId);

        let heygenAvatarId;
        let heygenVoiceId;

        if (isSiddharthVora) {
          heygenAvatarId =
            options.heygenAvatarId ||
            process.env.HEYGEN_AVATAR_ID_SIDDHARTH ||
            process.env.HEYGEN_AVATAR_ID ||
            SIDDHARTH_AVATAR_ID;
          heygenVoiceId =
            options.heygenVoiceId ||
            options.avatarVoiceId ||
            process.env.HEYGEN_VOICE_ID_SIDDHARTH ||
            process.env.HEYGEN_VOICE_ID ||
            SIDDHARTH_VOICE_ID;
        } else if (isGroupIdAvatar) {
          heygenAvatarId = options.heygenAvatarId || options.avatarId;
          heygenVoiceId =
            options.heygenVoiceId ||
            options.avatarVoiceId ||
            this._getVoiceIdFromAvatarMapping(options.avatarId);
          if (!heygenVoiceId) {
            throw new Error(`HeyGen voice not found for avatar ${options.avatarId}. Pass avatarVoiceId or add voiceId in config/heygen-native-voice-mapping.json`);
          }
        } else {
          heygenAvatarId = options.heygenAvatarId || process.env.HEYGEN_AVATAR_ID_SIDDHARTH || process.env.HEYGEN_AVATAR_ID || SIDDHARTH_AVATAR_ID;
          heygenVoiceId = options.heygenVoiceId || options.avatarVoiceId || process.env.HEYGEN_VOICE_ID_SIDDHARTH || process.env.HEYGEN_VOICE_ID || SIDDHARTH_VOICE_ID;
        }

        if (!heygenAvatarId) {
          throw new Error('HeyGen avatar ID not configured. Set HEYGEN_AVATAR_ID_SIDDHARTH or pass heygenAvatarId');
        }
        if (!heygenVoiceId) {
          throw new Error('HeyGen voice ID not configured. Set HEYGEN_VOICE_ID_SIDDHARTH or pass heygenVoiceId');
        }

        console.log(`   ðŸ‘¤ HeyGen Avatar ID: ${heygenAvatarId}`);
        console.log(`   ðŸŽ™ï¸  HeyGen Voice ID: ${heygenVoiceId}`);

        let heygenResult; // Declare result variable for HeyGen section

        try {
          // Generate HeyGen video using MCP tool
          const apiResult = await this._callMcpTool('mcp__heygen__generate_avatar_video', {
            avatar_id: heygenAvatarId,
            voice_id: heygenVoiceId,
            input_text: scriptText,
            title: options.title || `Avatar Video - ${options.topic || 'Content'}`
          });

          console.log(`   âœ… HeyGen video generation started`);
          console.log(`   Video ID: ${apiResult.video_id}`);

          // Build result object
          heygenResult = {
            videoUrl: null,
            localPath: null,
            duration: requestedDuration,
            metadata: {
              type: 'heygen-avatar',
              videoId: apiResult.video_id,
              status: 'pending',
              avatar: 'siddharth-vora',
              message: 'Video generation started. Check status with video ID or at https://app.heygen.com/home'
            }
          };

          // Wait for completion if requested
          if (options.waitForCompletion !== false) {
            console.log(`   â³ Waiting for HeyGen video to complete...`);

            let status = 'pending';
            let attempts = 0;
            const maxAttempts = 60; // 5 minutes max wait (5s intervals)

            while (status === 'pending' && attempts < maxAttempts) {
              await new Promise(resolve => setTimeout(resolve, 5000)); // Wait 5s

              const statusResult = await this._callMcpTool('mcp__heygen__get_avatar_video_status', {
                video_id: heygenResult.metadata.videoId
              });

              status = statusResult.status;
              console.log(`   Status: ${status} (${attempts + 1}/${maxAttempts})`);

              attempts++;
            }

            if (status === 'completed') {
              const finalStatus = await this._callMcpTool('mcp__heygen__get_avatar_video_status', {
                video_id: heygenResult.metadata.videoId
              });

              heygenResult = {
                videoUrl: finalStatus.video_url,
                localPath: null, // HeyGen videos are cloud-hosted
                duration: requestedDuration,
                metadata: {
                  type: 'heygen-avatar',
                  videoId: heygenResult.metadata.videoId,
                  avatar: 'siddharth-vora'
                }
              };

              console.log(`   âœ… HeyGen video completed: ${finalStatus.video_url}`);
            } else {
              console.log(`   âš ï¸  HeyGen video still processing. Check status later at https://app.heygen.com/home`);
              heygenResult.metadata.status = status;
              heygenResult.metadata.message = 'Video is still processing. Check HeyGen dashboard for status.';
            }
          } else {
            console.log(`   â„¹ï¸  HeyGen video generation started (async mode)`);
            console.log(`   Video ID: ${heygenResult.metadata.videoId}`);
          }
        } catch (error) {
          throw new Error(`HeyGen avatar video generation failed: ${error.message}`);
        }

        // Skip to final return
        console.log(`\nâœ… HeyGen avatar video generation completed!`);
        if (heygenResult.videoUrl) {
          console.log(`   Video URL: ${heygenResult.videoUrl}`);
        }
        console.log(`   Duration: ${heygenResult.duration}s`);

        return {
          success: true,
          videoUrl: heygenResult.videoUrl,
          localPath: heygenResult.localPath,
          hostedUrl: heygenResult.videoUrl, // HeyGen videos are already hosted
          duration: heygenResult.duration,
          metadata: heygenResult.metadata
        };
      }

      // Determine if we should use scene extension (for VEO videos > 8s)
      const shouldUseSceneExtension = !useLongCat &&
                                       options.useVeo !== false &&
                                       requestedDuration > 8 &&
                                       requestedDuration <= 148;

      let result;

      if (shouldUseSceneExtension && scenePrompts && scenePrompts.length > 1) {
        // Use scene-based generation with motion timeline
        console.log(`\nðŸ“¹ Generating video with scene extension...`);
        console.log(`   Provider: VEO 3.1 (Scene Extension)`);
        console.log(`   Total Scenes: ${scenePrompts.length}`);
        console.log(`   Target Duration: ${requestedDuration}s`);
        console.log(`   Estimated Duration: ${8 + (scenePrompts.length - 1) * 7}s\n`);

        // Initialize VEO generator
        const VideoGenerator = require('../video/video-generator');
        const veoGenerator = new VideoGenerator({
          apiKey: process.env.GEMINI_API_KEY,
          simulate: this.simulate
        });

        const veoConfig = {
          aspectRatio: options.aspectRatio || '16:9',
          resolution: '720p',
          // According to Veo 3.1 docs: Text-to-video & Extension require "allow_all" only
          // For faceless videos, we use "allow_all" but rely on prompt constraints ("NO PEOPLE, NO FACES, NO HUMANS")
          // For avatar videos, we also use "allow_all" (text-to-video mode)
          personGeneration: 'allow_all'  // Required for text-to-video mode (Veo 3.1)
        };

        result = await veoGenerator.generateLongVideo(
          scenePrompts[0],  // Base prompt (8s)
          scenePrompts.slice(1),  // Extension prompts (7s each)
          veoConfig
        );

        // Normalize result to match coordinator format
        result = {
          videoUrl: result.finalVideoUri,
          localPath: result.finalVideoUri,
          duration: result.totalDuration,
          metadata: {
            type: 'long-video',
            totalClips: result.totalClips,
            sceneCount: scenePrompts.length
          }
        };

      } else if (shouldUseSceneExtension && !scenePrompts) {
        // Auto-generate scene variations for default prompts
        console.log(`\nðŸ“¹ Generating video with auto scene extension...`);
        console.log(`   Provider: VEO 3.1 (Scene Extension)`);
        console.log(`   Target Duration: ${requestedDuration}s`);
        console.log(`   Mode: ${isAvatarMode ? 'Avatar' : 'Faceless'}`);

        const avatarScript = options.scriptText || options.avatarScriptText;
        const autoScenePrompts = this._generateAutoScenePrompts(prompt, requestedDuration, isAvatarMode, avatarScript);
        console.log(`   Auto Scenes: ${autoScenePrompts.length}\n`);

        // Initialize VEO generator
        const VideoGenerator = require('../video/video-generator');
        const veoGenerator = new VideoGenerator({
          apiKey: process.env.GEMINI_API_KEY,
          simulate: this.simulate
        });

        const veoConfig = {
          aspectRatio: options.aspectRatio || '16:9',
          resolution: '720p',
          // According to Veo 3.1 docs: Text-to-video & Extension require "allow_all" only
          // For faceless videos, we use "allow_all" but rely on prompt constraints ("NO PEOPLE, NO FACES, NO HUMANS")
          // For avatar videos, we also use "allow_all" (text-to-video mode)
          personGeneration: 'allow_all'  // Required for text-to-video mode (Veo 3.1)
        };

        result = await veoGenerator.generateLongVideo(
          autoScenePrompts[0],
          autoScenePrompts.slice(1),
          veoConfig
        );

        result = {
          videoUrl: result.finalVideoUri,
          localPath: result.finalVideoUri,
          duration: result.totalDuration,
          metadata: {
            type: 'long-video',
            totalClips: result.totalClips,
            sceneCount: autoScenePrompts.length
          }
        };

      } else {
        // Standard single-prompt generation (LongCat or short VEO)
        const videoConfig = {
          prompt: prompt,
          duration: requestedDuration,
          mode: longCatMode,
          aspectRatio: options.aspectRatio || '16:9',
          useLongCat: useLongCat,
          useVeo: options.useVeo && !useLongCat
        };

        console.log(`\nðŸ“¹ Generating video...`);
        console.log(`   Provider: ${useLongCat ? 'LongCat (fal.ai)' : options.useVeo ? 'VEO 3.1' : 'Auto'}`);
        console.log(`   Mode: ${videoConfig.mode}`);

        result = await coordinator.generateVideo(videoConfig);
      }

      console.log(`\nâœ… Video generation completed!`);
      console.log(`   Video path: ${result.localPath || result.videoUrl}`);
      console.log(`   Duration: ${result.duration}s`);

      // NEW: Upload video to Cloudinary for hosting
      let hostedVideoUrl = null;

      if (result.localPath && fs.existsSync(result.localPath)) {
        hostedVideoUrl = await this._uploadVideoToCloudinary(result.localPath);

        if (hostedVideoUrl) {
          result.hostedUrl = hostedVideoUrl;
        }
      } else if (result.videoUrl && result.videoUrl.startsWith('http')) {
        // If video is already hosted (e.g., HeyGen), use that URL
        hostedVideoUrl = result.videoUrl;
        console.log(`   â„¹ï¸  Video already hosted: ${hostedVideoUrl}`);
      }

      return {
        success: true,
        videoUrl: result.videoUrl,
        localPath: result.localPath,
        hostedUrl: hostedVideoUrl,  // Add hosted URL for WhatsApp
        duration: result.duration,
        metadata: result.metadata
      };

    } catch (error) {
      console.error(`\nâŒ Video production failed: ${error.message}`);

      // Check for missing API keys
      if (error.message.includes('FAL_KEY')) {
        console.error('   Set FAL_KEY environment variable for LongCat video generation');
      }
      if (error.message.includes('GEMINI_API_KEY')) {
        console.error('   Set GEMINI_API_KEY environment variable for VEO video generation');
      }

      return { success: false, error: error.message };
    }
  }

  /**
   * Build video generation prompt based on options.
   * Uses Veo 3.1 formula: [Cinematography] + [Subject] + [Action] + [Context] + [Style & Ambiance].
   * Faceless only: no people, faces, or humans.
   */
  _buildVideoPrompt(options) {
    const { platform, format, topic, type, language = 'english' } = options;
    const languageName = this._getLanguageName(language);
    const t = topic || 'financial insights';
    const languageInstruction = language !== 'english'
      ? ` On-screen text and labels in ${languageName}.`
      : '';

    // Veo 3.1-style: cinematography + subject + action + context + style; faceless motion graphics only
    const basePrompts = {
      linkedin: `Wide shot, abstract data visualizations and animated charts, rising and evolving across the frame, on a deep navy gradient background with soft blue and teal glow, corporate motion-graphics style, clean and premium. No people, faces, or humans. 16:9. Topic: ${t}.${languageInstruction}`,

      instagram: `Close-up to wide shot, animated line graph and dashboard-style metric tiles, sweeping left to right and fading in with ease-out motion, on a deep navy to blue gradient canvas with subtle teal accents, clean motion graphics and kinetic typography for Indian finance audience. No people, faces, or humans. 9:16 vertical, punchy and loopable. Topic: ${t}.${languageInstruction}`,

      youtube: (() => {
        const isShort = /short/i.test(format || '') || /youtube-short/i.test(type || '');
        if (isShort) {
          return `Tracking shot, animated charts and bold text cards, appearing in sequence with quick zooms and transitions, on high-contrast navy and teal background, kinetic typography and modern finance look. No people, faces, or humans. 9:16 vertical. Topic: ${t}.${languageInstruction}`;
        }
        return `Wide shot, step-by-step animated diagrams and 3D charts, building and transitioning smoothly, on a clean dark gradient with soft lighting, educational motion graphics and clear visual hierarchy. No people, faces, or humans. 16:9. Topic: ${t}.${languageInstruction}`;
      })(),

      facebook: `Medium shot, friendly animated graphics and icon-based visuals, gently animating and transitioning, on a warm gradient background, accessible motion graphics and clear messaging. No people, faces, or humans.${languageInstruction}`,

      twitter: `Close-up, animated statistics and data visualizations, quick cuts and bold transitions, on high-contrast background, minimal motion graphics. No people, faces, or humans. Topic: ${t}.${languageInstruction}`,

      whatsapp: `High-contrast, text-forward static image for WhatsApp about ${topic || 'your offer'}. 1080x1920 portrait-friendly layout, bold headline, single CTA, clear brand colors.${languageInstruction}`
    };

    return basePrompts[platform] || basePrompts.linkedin;
  }

  /**
   * Build video prompt from structured JSON format
   * Converts detailed JSON prompt structure into comprehensive text prompt for Veo
   * @private
   * @param {object} promptData - Structured prompt data
   * @returns {string} Formatted text prompt
   */
  _buildPromptFromJson(promptData) {
    const parts = [];

    // Product/Brand context
    if (promptData.brand) {
      parts.push(`${promptData.brand} brand video`);
    }
    if (promptData.product) {
      parts.push(`showcasing ${promptData.product}`);
    }

    // Description
    if (promptData.description) {
      parts.push(`- ${promptData.description}`);
    }

    // Style attributes
    if (promptData.style) {
      const styleDesc = Array.isArray(promptData.style)
        ? promptData.style.join(', ')
        : promptData.style;
      parts.push(`Style: ${styleDesc}.`);
    }

    // Camera work
    if (promptData.camera) {
      const cameraDesc = Array.isArray(promptData.camera)
        ? promptData.camera.join(', ')
        : promptData.camera;
      parts.push(`Camera: ${cameraDesc}.`);
    }

    // Lighting
    if (promptData.lighting) {
      const lightingDesc = Array.isArray(promptData.lighting)
        ? promptData.lighting.join(', ')
        : promptData.lighting;
      parts.push(`Lighting: ${lightingDesc}.`);
    }

    // Environment
    if (promptData.environment) {
      parts.push(`Environment: ${promptData.environment}.`);
    }

    // Color palette
    if (promptData.color_palette && promptData.color_palette.length > 0) {
      parts.push(`Colors: ${promptData.color_palette.join(', ')}.`);
    }

    // Visual elements
    if (promptData.elements && promptData.elements.length > 0) {
      parts.push(`Elements: ${promptData.elements.join(', ')}.`);
    }

    // Motion timeline (convert object to narrative)
    if (promptData.motion && typeof promptData.motion === 'object') {
      parts.push('\nMotion sequence:');
      Object.entries(promptData.motion).forEach(([timeRange, action]) => {
        parts.push(`${timeRange}: ${action}`);
      });
    }

    // Ending
    if (promptData.ending) {
      parts.push(`\nEnding: ${promptData.ending}.`);
    }

    // Explicit constraints
    const constraints = [];
    if (promptData.text !== undefined) {
      if (promptData.text === 'none' || promptData.text === null) {
        constraints.push('No text on screen');
      } else if (promptData.text) {
        constraints.push(`Text: "${promptData.text}"`);
      }
    }
    if (promptData.audio !== undefined) {
      if (promptData.audio === 'none' || promptData.audio === null) {
        constraints.push('No audio');
      } else if (promptData.audio) {
        constraints.push(`Audio: ${promptData.audio}`);
      }
    }
    if (constraints.length > 0) {
      parts.push(`\nConstraints: ${constraints.join(', ')}.`);
    }

    // Keywords for emphasis
    if (promptData.keywords && promptData.keywords.length > 0) {
      parts.push(`\nKeywords: ${promptData.keywords.join(', ')}.`);
    }

    // Duration
    if (promptData.duration) {
      parts.push(`\nDuration: ${promptData.duration} seconds.`);
    }

    return parts.join(' ');
  }

  /**
   * Upload video to Cloudinary for hosting
   * @private
   * @param {string} videoPath - Local path to video file
   * @returns {Promise<string|null>} Hosted video URL or null on failure
   */
  async _uploadVideoToCloudinary(videoPath) {
    // Parse Cloudinary URL: cloudinary://API_KEY:API_SECRET@CLOUD_NAME
    const cloudinaryUrl = process.env.CLOUDINARY_URL;

    if (!cloudinaryUrl) {
      console.log('   âš ï¸  CLOUDINARY_URL not configured. Set it to upload videos.');
      return null;
    }

    try {
      // Parse credentials from URL
      const urlMatch = cloudinaryUrl.match(/cloudinary:\/\/(\d+):([^@]+)@(.+)/);
      if (!urlMatch) {
        console.log('   âš ï¸  Invalid CLOUDINARY_URL format');
        return null;
      }

      const [, apiKey, apiSecret, cloudName] = urlMatch;

      console.log('   â˜ï¸  Uploading video to Cloudinary...');

      // Use official Cloudinary SDK for reliable uploads
      const cloudinary = require('cloudinary').v2;
      cloudinary.config({
        cloud_name: cloudName,
        api_key: apiKey,
        api_secret: apiSecret
      });

      const result = await cloudinary.uploader.upload(videoPath, {
        resource_type: 'video',
        folder: 'social-media'
      });

      const hostedUrl = result.secure_url;

      if (hostedUrl) {
        console.log(`   âœ… Video uploaded to Cloudinary: ${hostedUrl}`);
        console.log(`      Public ID: ${result.public_id}`);
        console.log(`      Duration: ${result.duration}s`);
        console.log(`      Size: ${(result.bytes / 1024 / 1024).toFixed(2)} MB`);
        return hostedUrl;
      }

      return null;
    } catch (error) {
      console.log(`   âš ï¸  Cloudinary upload error: ${error.message}`);
      return null;
    }
  }

  async stagePublishing(options) {
    console.log('ðŸ“¤ Stage 5: Multi-Platform Publishing');
    console.log(`   Platform: ${options.platform || 'all'}\n`);

    if (this.simulate) {
      console.log('   [SIMULATED] Content published');
      return;
    }

    // Email newsletter publishing via MoEngage
    const isEmailNewsletter = (options.platform && options.platform.includes('email')) ||
      (options.type && options.type.includes('email'));

    const isWhatsApp = options.platform && options.platform.includes('whatsapp');

    try {
      const publisher = getMoengageEmailPublisher();
      const newsletter = publisher.loadLatestNewsletter(options.topic);

      if (isEmailNewsletter || newsletter) {
        if (!newsletter) {
          console.log('   âš ï¸  No email newsletter content found in workflow-state.json');
          return;
        }

        console.log(`   ðŸ“§ Publishing newsletter via MoEngage (subject: ${newsletter.subject})...`);
        await publisher.publishNewsletter({
          ...newsletter,
          topic: newsletter.topic || options.topic
        });
        console.log('   âœ… Newsletter push sent to MoEngage (SendGrid-backed campaign)');
        return;
      }

      if (isWhatsApp) {
        const creativeUrl = options.creativeUrl || options.whatsappImageUrl || options.whatsappVideoUrl;
        const cta = options.cta || options.whatsappCta;

        if (!creativeUrl) {
          console.log('   âš ï¸  No WhatsApp creative URL provided; skipping WhatsApp push.');
          console.log('   ðŸ’¡ Tip: For images, pass options.whatsappImageUrl (from stageContent result)');
          console.log('   ðŸ’¡ Tip: For videos, pass options.whatsappVideoUrl (from stageVideo hostedUrl)');
          console.log('   ðŸ’¡ Example: await stagePublishing({ platform: "whatsapp", whatsappVideoUrl: videoResult.hostedUrl })');
          return;
        }

        const isVideo = creativeUrl.includes('.mp4') || creativeUrl.includes('video') || options.whatsappVideoUrl;
        const mediaType = isVideo ? 'video' : 'image';

        console.log(`   ðŸ’¬ Publishing WhatsApp ${mediaType} via MoEngage (event: WhatsAppCreativeReady)...`);
        console.log(`   ðŸ”— Creative URL: ${creativeUrl.substring(0, 60)}...`);

        await publisher.publishWhatsAppCreative({
          topic: options.topic,
          creativeUrl,
          cta
        });
        console.log(`   âœ… WhatsApp ${mediaType} push sent to MoEngage (Interakt-backed campaign expected)`);
        return;
      }
    } catch (error) {
      console.error(`   âŒ MoEngage publish failed: ${error.message}`);
      return;
    }

    // TODO: Implement other platform publishing integrations
    console.log('   âš ï¸  Publishing not yet implemented for non-email platforms');
  }

  async stageTracking(options) {
    console.log('ðŸ“Š Stage 6: Performance Tracking');

    if (this.simulate) {
      console.log('   [SIMULATED] Metrics tracked');
      return;
    }

    // MoEngage reporting for WhatsApp/Email (requires MOENGAGE_* env)
    const isWhatsApp = options.platform && options.platform.includes('whatsapp');
    const isEmail = options.platform && options.platform.includes('email');

    if (isWhatsApp || isEmail) {
      try {
        const client = getMoengageClient();
        const now = Date.now();
        const fromTs = now - 24 * 60 * 60 * 1000;
        const params = {
          event_name: isWhatsApp ? 'WhatsAppCreativeReady' : 'EmailNewsletterReady',
          from: fromTs,
          to: now,
          limit: 50
        };

        console.log('   ðŸ“¡ Fetching MoEngage business events for last 24h...');
        const data = await client.getBusinessEvents(params);
        console.log(`   âœ… Retrieved ${Array.isArray(data?.data) ? data.data.length : 0} events`);
        if (Array.isArray(data?.data) && data.data.length) {
          const recent = data.data.slice(0, 5);
          recent.forEach((item, idx) => {
            console.log(`     [${idx + 1}] ${item.event_name || 'event'} :: ${item.event_timestamp || ''}`);
          });
        }
      } catch (error) {
        console.error(`   âŒ MoEngage tracking fetch failed: ${error.message}`);
      }
    } else {
      console.log('   âš ï¸  Tracking not yet implemented for this platform');
    }
  }

  /**
   * Placeholder campaign handlers
   */

  async runLinkedInDataViz(options) {
    console.log('ðŸ“Š LinkedIn Data Viz - Not yet implemented');
  }

  async runInstagramCarousel(options) {
    console.log('ðŸ“¸ Instagram Carousel - Not yet implemented');
  }

  async runYouTubeShort(options) {
    console.log('ðŸ“± YouTube Short - Not yet implemented');
  }

  async runFacebookReel(options) {
    console.log('ðŸ“± Facebook Reel Campaign');
    console.log(`   Topic: ${options.topic}`);
    console.log(`   Duration: ${options.duration}s\n`);

    // Same flow as Instagram Reel: short-form vertical video for Facebook
    await this.stageContent({
      platform: 'facebook',
      format: 'reel',
      topic: options.topic,
      duration: options.duration,
      language: options.language
    });

    await this.stageVideo({
      platform: 'facebook',
      format: 'reel',
      aspectRatio: options.aspectRatio || '9:16',
      duration: options.duration,
      useVeo: options.useVeo,
      useAvatar: options.useAvatar,
      language: options.language,
      waitForCompletion: options.waitForCompletion
    });

    if (options.autoPublish) {
      await this.stagePublishing({ platform: 'facebook' });
    }

    console.log('\nâœ… Facebook reel ready!');
  }

  async runTwitterThread(options) {
    console.log('ðŸ¦ Twitter/X Thread Campaign');
    console.log(`   Topic: ${options.topic}`);
    if (options.language) {
      console.log(`   Language: ${this._getLanguageName(options.language)}`);
    }
    console.log('');

    // Stage 2: Generate thread content (tweets), save to state
    await this.stageContent({
      platform: 'twitter',
      format: 'thread',
      topic: options.topic,
      language: options.language
    });

    if (options.autoPublish) {
      await this.stagePublishing({ platform: 'twitter' });
    }

    console.log('\nâœ… Twitter thread ready!');
  }

  async runEmailNewsletter(options) {
    console.log('ðŸ“§ Email Newsletter Campaign');
    console.log(`   Topic: ${options.topic}\n`);

    await this.stageContent({
      platform: 'email',
      format: 'newsletter',
      topic: options.topic,
      type: 'email-newsletter',
      language: options.language
    });

    await this.stagePublishing({
      platform: 'email',
      type: 'email-newsletter',
      topic: options.topic
    });

    console.log('\nâœ… Email newsletter publishing trigger sent!\n');
  }

  /**
   * Extract scene-specific prompts from JSON motion timeline
   * Converts motion timeline object into array of scene prompts for VEO extension
   * @private
   * @param {object} promptData - Full JSON prompt data
   * @returns {Array<string>} Array of scene prompts [base, extension1, extension2...]
   */
  _extractScenePromptsFromJson(promptData) {
    const scenePrompts = [];

    // Build base context (brand, product, style, etc.) to apply to all scenes
    const baseContext = [];
    if (promptData.brand) baseContext.push(`${promptData.brand} brand video`);
    if (promptData.product) baseContext.push(`showcasing ${promptData.product}`);
    if (promptData.description) baseContext.push(promptData.description);

    const styleElements = [];
    if (promptData.style) {
      const styleDesc = Array.isArray(promptData.style) ? promptData.style.join(', ') : promptData.style;
      styleElements.push(`Style: ${styleDesc}`);
    }
    if (promptData.lighting) {
      const lightingDesc = Array.isArray(promptData.lighting) ? promptData.lighting.join(', ') : promptData.lighting;
      styleElements.push(`Lighting: ${lightingDesc}`);
    }
    if (promptData.environment) {
      styleElements.push(`Environment: ${promptData.environment}`);
    }
    if (promptData.color_palette && promptData.color_palette.length > 0) {
      styleElements.push(`Colors: ${promptData.color_palette.join(', ')}`);
    }
    if (promptData.elements && promptData.elements.length > 0) {
      styleElements.push(`Elements: ${promptData.elements.join(', ')}`);
    }

    const constraints = [];
    if (promptData.text === 'none' || promptData.text === null) {
      constraints.push('No text on screen');
    }
    if (promptData.keywords && promptData.keywords.length > 0) {
      constraints.push(`Keywords: ${promptData.keywords.join(', ')}`);
    }

    // Sort motion timeline entries by time (e.g., "0-1s", "1-3s", "3-5s")
    const motionEntries = Object.entries(promptData.motion).sort((a, b) => {
      const aStart = parseInt(a[0].split('-')[0]);
      const bStart = parseInt(b[0].split('-')[0]);
      return aStart - bStart;
    });

    // Group timeline entries into scenes (base = first ~8s of motion, extensions = ~7s each)
    const baseMotion = [];
    const extensionMotions = [];

    motionEntries.forEach(([timeRange, action], index) => {
      if (index === 0 || index === 1) {
        // First 2 entries = base scene (8s)
        baseMotion.push(`${timeRange}: ${action}`);
      } else {
        // Subsequent entries = extensions (7s each)
        extensionMotions.push({ timeRange, action });
      }
    });

    // Build base scene prompt (8s)
    const basePrompt = [
      ...baseContext,
      ...styleElements,
      `Motion: ${baseMotion.map(m => m).join('; ')}`,
      constraints.join(', ')
    ].filter(Boolean).join('. ') + '.';

    scenePrompts.push(basePrompt);

    // Build extension prompts (7s each)
    extensionMotions.forEach(({ timeRange, action }) => {
      const extensionPrompt = [
        ...baseContext,
        ...styleElements,
        `${timeRange}: ${action}`,
        constraints.join(', ')
      ].filter(Boolean).join('. ') + '.';

      scenePrompts.push(extensionPrompt);
    });

    return scenePrompts;
  }

  /**
   * Auto-generate scene variations from a single prompt (Veo 3.1 best practices)
   * Creates base + extension prompts for scene extension without JSON timeline.
   * Extension prompts follow Veo 3.1 format: continuation + segment timing + (avatar: script chunk) + cinematography + constraints.
   * @private
   * @param {string} basePrompt - The original video prompt (already Veo 3.1-style from _buildVideoPrompt)
   * @param {number} targetDuration - Desired video duration in seconds
   * @param {boolean} isAvatarMode - Whether this is avatar video (vs faceless)
   * @param {string} [avatarScript] - Full script for avatar mode; split by segment for extension prompts
   * @returns {Array<string>} Array of scene prompts [base, extensions...]
   */
  _generateAutoScenePrompts(basePrompt, targetDuration, isAvatarMode = false, avatarScript = null) {
    // Base = 8s, each extension = 7s (Veo 3.1)
    const extensionsNeeded = Math.max(0, Math.ceil((targetDuration - 8) / 7));
    const scenePrompts = [basePrompt];

    // Split script by segment for avatar extensions (~2.2 words/sec for clear speech)
    const wordsPerBase = Math.round(8 * 2.2);   // ~18 words for 8s
    const wordsPerExtension = Math.round(7 * 2.2); // ~15 words per 7s
    let scriptChunks = [];
    if (isAvatarMode && avatarScript && typeof avatarScript === 'string') {
      const words = avatarScript.trim().split(/\s+/).filter(Boolean);
      let start = wordsPerBase;
      for (let i = 0; i < extensionsNeeded && i < 20; i++) {
        const end = Math.min(start + wordsPerExtension, words.length);
        scriptChunks.push(words.slice(start, end).join(' '));
        start = end;
      }
    }

    // Veo 3.1 extension best practices: continuation + segment timing + cinematography + same constraints
    const facelessVariations = [
      'Camera orbits around the visual elements with dynamic lighting transitions',
      'Zoom into key data points revealing intricate details and patterns',
      'Visual elements reorganize and transform with smooth animated transitions',
      'Camera pulls back to reveal full scene with enhanced lighting effects',
      'Data elements pulse and animate with synchronized motion',
      'Cinematic rotation showcasing different angles and perspectives',
      'Volumetric lighting reveals hidden layers and depth',
      'Elements coalesce and disperse in fluid choreographed motion'
    ];

    const avatarVariations = [
      'Camera slowly pushes in to medium close-up, maintaining eye contact and professional framing',
      'Subtle camera dolly right revealing more of the background environment',
      'Camera pulls back to medium wide shot showing full upper body and gestures',
      'Slight camera tilt up with natural subject movement and confident delivery',
      'Camera slowly pans left while subject maintains engagement with viewer',
      'Gentle camera push in to close-up emphasizing facial expressions and sincerity',
      'Camera arc right to slightly off-center angle adding dynamic visual interest',
      'Slow zoom out revealing professional office setting with subject centered'
    ];

    const variations = isAvatarMode ? avatarVariations : facelessVariations;

    for (let i = 0; i < extensionsNeeded && i < 20; i++) {
      const segmentStart = 8 + i * 7;
      const segmentEnd = segmentStart + 7;
      const timeRange = `Segment ${segmentStart}-${segmentEnd}s`;
      const variation = variations[i % variations.length];

      if (isAvatarMode) {
        // Avatar: continuation + segment + script for this segment + camera variation + same speaker/setting
        const scriptChunk = scriptChunks[i];
        const scriptPart = scriptChunk
          ? `Speaking the next part of the script: "${scriptChunk}". `
          : '';
        scenePrompts.push(
          `Continue the same shot. ${timeRange}. ${scriptPart}${variation}. Same speaker, setting, and professional delivery.`
        );
      } else {
        // Faceless: continuation + segment + cinematography + reinforce NO PEOPLE (Veo 3.1 best practice)
        scenePrompts.push(
          `Continue the same scene. ${timeRange}. ${variation}. Same subject, style, and visual language. NO PEOPLE, NO FACES, NO HUMANS.`
        );
      }
    }

    return scenePrompts;
  }

  /**
   * Resolve HeyGen voiceId for a groupId from the same mapping the frontend uses
   * (/api/avatars reads config/heygen-native-voice-mapping.json or avatar-voice-mapping.json)
   * @private
   * @param {string} groupId - HeyGen avatar group ID (32 hex chars)
   * @returns {string|null} voiceId or null if not found
   */
  _getVoiceIdFromAvatarMapping(groupId) {
    if (!groupId || typeof groupId !== 'string') return null;
    const configPaths = [
      path.join(this.projectRoot, 'backend', 'config', 'heygen-native-voice-mapping.json'),
      path.join(this.projectRoot, 'config', 'heygen-native-voice-mapping.json'),
      path.join(this.projectRoot, 'backend', 'config', 'avatar-voice-mapping.json')
    ];
    for (const configPath of configPaths) {
      try {
        if (fs.existsSync(configPath)) {
          const raw = fs.readFileSync(configPath, 'utf8');
          const mapping = JSON.parse(raw);
          const entry = mapping[groupId] || (typeof mapping === 'object' && mapping.avatars ? mapping.avatars[groupId] : null);
          const voiceId = entry?.voiceId || null;
          if (voiceId) return voiceId;
        }
      } catch (_) { /* ignore */ }
    }
    return null;
  }

  /**
   * Call HeyGen API for avatar video generation and status checking
   * Routes to HeyGen's REST API based on tool name
   * @private
   * @param {string} toolName - Name of the tool to call
   * @param {object} params - Parameters to pass to the tool
   * @returns {Promise<object>} Tool result
   */
  async _callMcpTool(toolName, params) {
    const apiKey = process.env.HEYGEN_API_KEY;

    if (!apiKey) {
      throw new Error('HEYGEN_API_KEY environment variable is required');
    }

    // Route to appropriate HeyGen API endpoint
    if (toolName === 'mcp__heygen__generate_avatar_video') {
      return await this._heygenGenerateVideo(apiKey, params);
    } else if (toolName === 'mcp__heygen__get_avatar_video_status') {
      return await this._heygenGetVideoStatus(apiKey, params);
    } else {
      throw new Error(`Unknown MCP tool: ${toolName}`);
    }
  }

  /**
   * Generate HeyGen avatar video
   * @private
   */
  async _heygenGenerateVideo(apiKey, params) {
    const { avatar_id, voice_id, input_text, title } = params;

    const requestBody = {
      video_inputs: [{
        character: {
          type: 'avatar',
          avatar_id: avatar_id,
          avatar_style: 'normal'
        },
        voice: {
          type: 'text',
          input_text: input_text,
          voice_id: voice_id
        }
      }],
      dimension: {
        width: 1280,
        height: 720
      },
      title: title || 'Avatar Video'
    };

    console.log(`   ðŸ” HeyGen API Request:`);
    console.log(`      Endpoint: POST https://api.heygen.com/v2/video/generate`);
    console.log(`      Body: ${JSON.stringify(requestBody, null, 2).substring(0, 200)}...`);

    const response = await fetch('https://api.heygen.com/v2/video/generate', {
      method: 'POST',
      headers: {
        'X-Api-Key': apiKey,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(requestBody)
    });

    const responseText = await response.text();
    console.log(`   ðŸ“¡ HeyGen API Response (${response.status}): ${responseText.substring(0, 200)}...`);

    if (!response.ok) {
      throw new Error(`HeyGen API error: ${response.status} ${responseText}`);
    }

    const result = JSON.parse(responseText);

    // HeyGen API returns { error: null, data: { video_id: "..." } } on success
    // or { error: { code: "...", message: "..." }, data: null } on failure
    if (result.error) {
      throw new Error(`HeyGen video generation failed: ${result.error.message || JSON.stringify(result.error)}`);
    }

    if (!result.data?.video_id) {
      throw new Error(`HeyGen video generation failed: No video_id in response`);
    }

    console.log(`   âœ… HeyGen video initiated: ${result.data.video_id}`);

    return {
      video_id: result.data.video_id
    };
  }

  /**
   * Get HeyGen video status
   * @private
   */
  async _heygenGetVideoStatus(apiKey, params) {
    const { video_id } = params;

    const response = await fetch(`https://api.heygen.com/v1/video_status.get?video_id=${video_id}`, {
      method: 'GET',
      headers: {
        'X-Api-Key': apiKey
      }
    });

    const responseText = await response.text();

    if (!response.ok) {
      throw new Error(`HeyGen API error: ${response.status} ${responseText}`);
    }

    const result = JSON.parse(responseText);

    // HeyGen API returns { error: null, data: { status: "pending|completed|failed", video_url: "..." } }
    if (result.error) {
      throw new Error(`HeyGen status check failed: ${result.error.message || JSON.stringify(result.error)}`);
    }

    const status = result.data?.status || 'unknown';
    const videoUrl = result.data?.video_url || null;

    return {
      status: status,
      video_url: videoUrl
    };
  }
}

module.exports = SocialMediaOrchestrator;
